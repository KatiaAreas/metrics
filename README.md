# MÃ©triques de Comparaison de Nuages de Points et Cartes de Profondeur

Toolkit Python complet pour comparer des nuages de points (PLY) et des cartes de profondeur contre des modÃ¨les de rÃ©fÃ©rence STL.

## ğŸ“‹ Table des matiÃ¨res

- [Installation](#installation)
- [Vue d'ensemble](#vue-densemble)
- [Cas d'usage 1 : Comparaison PLY](#cas-1--comparaison-ply-vs-stl)
- [Cas d'usage 2 : Comparaison Depth Map](#cas-2--comparaison-depth-map-vs-stl)
- [Exemples dÃ©taillÃ©s](#exemples-dÃ©taillÃ©s)
- [MÃ©triques disponibles](#mÃ©triques-disponibles)
- [API Reference](#api-reference)

## ğŸ”§ Installation

```bash
pip install numpy trimesh scipy scikit-learn matplotlib seaborn plyfile
```

### DÃ©pendances

- `numpy` : Calculs numÃ©riques
- `trimesh` : Manipulation de meshes 3D et fichiers PLY/STL
- `scipy` : KD-tree pour recherches spatiales
- `scikit-learn` : Clustering (DBSCAN) et PCA
- `matplotlib` & `seaborn` : Visualisations
- `plyfile` : (Optionnel) Lecture alternative de fichiers PLY

## ğŸ¯ Vue d'ensemble

Ce toolkit fournit deux classes principales :

### 1. `PointCloudMetrics`
Compare un nuage de points accumulÃ© (PLY) contre un modÃ¨le STL de rÃ©fÃ©rence.
- **Use case** : Points dÃ©tectÃ©s manuellement par frame qui s'accumulent dans le temps
- **ProblÃ¨me** : 18 points attendus, mais bruit crÃ©ant des ellipses/cercles
- **MÃ©triques** : Dispersion des clusters + Distance au modÃ¨le STL

### 2. `DepthMapMetrics`
Compare une carte de profondeur (depth map) contre un modÃ¨le STL.
- **Use case** : Image de profondeur (nÃ—m) en mm, modÃ¨le STL en m
- **Processus** : DÃ©projection depth â†’ 3D via matrice [K RT]
- **MÃ©triques** : PrÃ©cision, complÃ©tude, cartes de chaleur

---

## ğŸ“Š Cas 1 : Comparaison PLY vs STL

### Contexte
Vous dÃ©tectez 18 points par frame. Ces points s'accumulent dans le temps pour former un fichier PLY. IdÃ©alement, vous devriez avoir 18 clusters bien dÃ©finis, mais le bruit crÃ©e des dispersions (ellipses/cercles) autour de chaque position thÃ©orique.

### MÃ©triques calculÃ©es

#### 1. **Clustering des points**
```python
clusters = metrics.cluster_points(eps=0.005, min_samples=3)
```
- Regroupe les points qui devraient reprÃ©senter la mÃªme position
- `eps` : distance maximale entre points d'un cluster (en mÃ¨tres)
- Retourne un dictionnaire avec centroides et points par cluster

#### 2. **Dispersion (quantification du bruit)**
```python
dispersion = metrics.compute_cluster_dispersion(clusters)
```

Pour chaque cluster, calcule :
- **Ã‰cart-type** : Dispersion dans chaque direction (x, y, z)
- **Distance moyenne au centroÃ¯de** : Mesure du bruit global
- **Distance maximale** : Worst-case du bruit
- **Axes de l'ellipse** (via PCA) : Dimensions de l'ellipse de dispersion
- **Ratio d'ellipse** : ellipse_axes[0] / ellipse_axes[1] (circularitÃ©)

#### 3. **Distance au modÃ¨le STL**
```python
distance_metrics = metrics.compute_point_to_surface_metrics(clusters)
```

- **RMSE** : Root Mean Square Error des distances
- **MAE** : Mean Absolute Error
- **Distance moyenne/mÃ©diane** : Statistiques centrales
- **Min/Max** : Plage des erreurs

#### 4. **MÃ©trique combinÃ©e**
```python
combined = metrics.compute_combined_metric(clusters, dispersion, 
                                          distance_metrics, alpha=0.5)
```

Formule : `erreur = Î± Ã— distance_au_STL + (1-Î±) Ã— dispersion_moyenne`
- `Î± = 0.5` : Poids Ã©gal entre prÃ©cision et bruit
- `Î± = 0.7` : Favorise la prÃ©cision (distance au STL)
- `Î± = 0.3` : Favorise la faible dispersion

### Exemple complet

```python
from point_cloud_metrics import PointCloudMetrics
import trimesh

# Charger le nuage de points PLY
ply_mesh = trimesh.load("points_accumules.ply")
ply_points = ply_mesh.vertices

# Initialiser avec le modÃ¨le de rÃ©fÃ©rence
metrics = PointCloudMetrics(ply_points, "modele_reference.stl")

# 1. Clustering
clusters = metrics.cluster_points(eps=0.005, min_samples=3)
print(f"Clusters trouvÃ©s : {len(clusters)} (attendu : 18)")

# 2. Analyser la dispersion
dispersion = metrics.compute_cluster_dispersion(clusters)
for cluster_id, disp in dispersion.items():
    print(f"Cluster {cluster_id}:")
    print(f"  Dispersion moyenne : {disp['mean_distance']*1000:.2f} mm")
    print(f"  Axes ellipse : {disp['ellipse_axes']*1000} mm")

# 3. Distance au STL
distance_metrics = metrics.compute_point_to_surface_metrics(clusters)
print(f"\nRMSE au STL : {distance_metrics['rmse']*1000:.3f} mm")

# 4. Rapport complet
report = metrics.generate_report(clusters)
print(report)

# 5. Visualisation
metrics.visualize_clusters(clusters, save_path="clusters.png")
```

### Sortie typique

```
Clusters trouvÃ©s : 18 (attendu : 18)

Cluster 0:
  Dispersion moyenne : 2.34 mm
  Axes ellipse : [3.1, 2.2, 1.8] mm
  
RMSE au STL : 1.56 mm
MÃ©trique combinÃ©e : 1.95 mm
```

---

## ğŸ—ºï¸ Cas 2 : Comparaison Depth Map vs STL

### Contexte
Vous avez une carte de profondeur (nÃ—m) en millimÃ¨tres (valeurs float non normalisÃ©es) et un modÃ¨le STL en mÃ¨tres. Vous devez :
1. DÃ©projeter la depth map en nuage 3D via les matrices [K RT]
2. Comparer le nuage 3D au modÃ¨le STL

### Pipeline

```
Depth Map (mm) â†’ [K, RT] â†’ Point Cloud 3D (m) â†’ Comparaison STL
```

### MÃ©triques calculÃ©es

#### 1. **DÃ©projection depth â†’ 3D**
```python
point_cloud = metrics.deproject_depth_to_3d()
```

Processus :
- Filtre les pixels invalides (depth = 0 ou NaN)
- Conversion mm â†’ m via `depth_scale`
- Utilise K (intrinsÃ¨ques) pour obtenir (x, y, z) en coordonnÃ©es camÃ©ra
- Applique [R|t] pour passer en coordonnÃ©es monde

Formule :
```
x_cam = (u - cx) Ã— z / fx
y_cam = (v - cy) Ã— z / fy
z_cam = z

P_world = R Ã— P_cam + t
```

#### 2. **MÃ©triques de prÃ©cision**
```python
accuracy = metrics.compute_accuracy_metrics()
```

- **RMSE** : Erreur quadratique moyenne
- **MAE** : Erreur absolue moyenne
- **Percentiles** (95e, 99e) : Distribution des erreurs
- **Ratio pixels valides** : Couverture de l'image

#### 3. **ComplÃ©tude (coverage)**
```python
completeness = metrics.compute_completeness(threshold=0.01)
```

Calcule le pourcentage de la surface STL qui est couverte par des points du nuage 3D :
- Ã‰chantillonne uniformÃ©ment la surface STL
- Pour chaque point STL, trouve le point le plus proche dans le nuage
- Compte combien sont dans le seuil de distance

RÃ©sultat : `85% de la surface couverte Ã  10mm prÃ¨s`

#### 4. **Carte de chaleur des erreurs**
```python
error_map = metrics.create_error_heatmap(save_path="heatmap.png")
```

Projette les distances point-to-mesh sur l'image depth originale pour visualiser spatialement les erreurs.

#### 5. **MÃ©triques par rÃ©gion**
```python
regions = [
    (slice(0, h//2), slice(0, w//2)),  # Quadrant haut-gauche
    ...
]
regional_metrics = metrics.compute_regional_metrics(regions)
```

Calcule les mÃ©triques sÃ©parÃ©ment pour diffÃ©rentes zones de l'image (utile si certaines rÃ©gions sont critiques).

### Exemple complet

```python
from point_cloud_metrics import DepthMapMetrics
import numpy as np
import cv2

# Charger la carte de profondeur (16-bit)
depth_map = cv2.imread("depth.png", cv2.IMREAD_ANYDEPTH).astype(np.float32)

# Matrice intrinsÃ¨que (exemple RealSense D435)
K = np.array([
    [615.0, 0, 320.0],
    [0, 615.0, 240.0],
    [0, 0, 1]
])

# Matrice extrinsÃ¨que [R|t]
RT = np.eye(4)
RT[:3, 3] = [0, 0, 1]  # Translation de 1m en Z

# Initialiser
metrics = DepthMapMetrics(
    depth_map=depth_map,
    K=K,
    RT=RT,
    stl_path="modele.stl",
    depth_scale=1000.0  # mm â†’ m
)

# 1. DÃ©projection
point_cloud = metrics.deproject_depth_to_3d()
print(f"Points gÃ©nÃ©rÃ©s : {len(point_cloud)}")

# 2. PrÃ©cision
accuracy = metrics.compute_accuracy_metrics()
print(f"RMSE : {accuracy['rmse']*1000:.2f} mm")
print(f"MAE : {accuracy['mae']*1000:.2f} mm")

# 3. ComplÃ©tude
completeness = metrics.compute_completeness(threshold=0.01)
print(f"Couverture surface : {completeness['completeness_percentage']:.1f}%")

# 4. Carte de chaleur
error_map = metrics.create_error_heatmap(save_path="heatmap.png")

# 5. Rapport complet
report = metrics.generate_report()
with open("rapport.txt", "w") as f:
    f.write(report)
```

### Sortie typique

```
Points gÃ©nÃ©rÃ©s : 245,328 / 307,200 pixels
RMSE : 3.45 mm
MAE : 2.78 mm
95e percentile : 8.92 mm
Couverture surface : 87.3%
```

---

## ğŸ“ˆ MÃ©triques disponibles

### MÃ©triques de dispersion (bruit)

| MÃ©trique | Description | UnitÃ© |
|----------|-------------|-------|
| `mean_std` | Ã‰cart-type moyen dans les 3 dimensions | mm |
| `mean_distance` | Distance moyenne au centroÃ¯de | mm |
| `max_distance` | Distance maximale au centroÃ¯de | mm |
| `ellipse_axes` | Dimensions de l'ellipse (PCA) | mm |
| `ellipse_ratio` | Ratio axes[0]/axes[1] (circularitÃ©) | - |

### MÃ©triques de prÃ©cision

| MÃ©trique | Description | Formule |
|----------|-------------|---------|
| `RMSE` | Root Mean Square Error | âˆš(Î£dÂ²/n) |
| `MAE` | Mean Absolute Error | Î£\|d\|/n |
| `Mean` | Distance moyenne | Î£d/n |
| `Median` | Distance mÃ©diane | quantile(50%) |
| `Std` | Ã‰cart-type | âˆš(Î£(d-Î¼)Â²/n) |
| `Percentile 95` | 95% des erreurs sous ce seuil | quantile(95%) |

### MÃ©triques de complÃ©tude

| MÃ©trique | Description |
|----------|-------------|
| `completeness_percentage` | % de surface STL couverte |
| `covered_points` | Nombre de points STL couverts |
| `threshold_m` | Seuil de distance utilisÃ© |

---

## ğŸ”¬ API Reference

### PointCloudMetrics

```python
PointCloudMetrics(ply_points: np.ndarray, stl_path: str)
```

**MÃ©thodes principales :**

- `cluster_points(eps, min_samples)` : Clustering DBSCAN
- `compute_cluster_dispersion(clusters)` : Calcul dispersion/bruit
- `compute_point_to_surface_metrics(clusters)` : Distance au STL
- `compute_combined_metric(clusters, dispersion, distance, alpha)` : MÃ©trique combinÃ©e
- `visualize_clusters(clusters, save_path)` : Visualisation 3D
- `generate_report(clusters)` : Rapport texte complet

### DepthMapMetrics

```python
DepthMapMetrics(depth_map: np.ndarray, K: np.ndarray, 
                RT: np.ndarray, stl_path: str, depth_scale: float)
```

**MÃ©thodes principales :**

- `deproject_depth_to_3d()` : Conversion depth â†’ 3D
- `compute_accuracy_metrics()` : RMSE, MAE, etc.
- `compute_completeness(threshold)` : % couverture surface
- `create_error_heatmap(save_path)` : Carte de chaleur 2D
- `compute_regional_metrics(regions)` : MÃ©triques par zone
- `generate_report()` : Rapport texte complet

---

## ğŸ¨ Visualisations gÃ©nÃ©rÃ©es

### 1. Clusters PLY (3D scatter + dispersion + distance STL)
![Exemple clusters](clusters_visualization.png)

### 2. Carte de chaleur des erreurs depth map
![Exemple heatmap](error_heatmap.png)

---

## ğŸ’¡ Conseils d'utilisation

### Ajuster les paramÃ¨tres de clustering

```python
# Bruit faible (points prÃ©cis)
clusters = metrics.cluster_points(eps=0.003, min_samples=5)

# Bruit Ã©levÃ© (points dispersÃ©s)
clusters = metrics.cluster_points(eps=0.010, min_samples=3)
```

### Filtrer les outliers

```python
# Supprimer les clusters avec trop peu de points
filtered = {k: v for k, v in clusters.items() if v['size'] >= 5}
```

### Seuils de complÃ©tude

```python
# Strict : 5mm
completeness_strict = metrics.compute_completeness(threshold=0.005)

# Permissif : 20mm
completeness_loose = metrics.compute_completeness(threshold=0.020)
```

### Analyser des rÃ©gions spÃ©cifiques

```python
# RÃ©gion centrale (plus importante)
h, w = depth_map.shape
center_region = [(slice(h//4, 3*h//4), slice(w//4, 3*w//4))]
center_metrics = metrics.compute_regional_metrics(center_region)
```

---

## ğŸ“ Format des fichiers

### EntrÃ©es acceptÃ©es

**PLY** :
- Format binaire ou ASCII
- Minimum : vertices (x, y, z)
- Chargeable via `trimesh` ou `plyfile`

**STL** :
- Format binaire ou ASCII
- Ã‰chelle : mÃ¨tres recommandÃ©

**Depth Map** :
- Array numpy 2D (nÃ—m)
- Type : `float32` ou `float64`
- UnitÃ© : millimÃ¨tres (ou spÃ©cifier `depth_scale`)
- Valeurs invalides : 0 ou NaN

**Matrices** :
- K : 3Ã—3 (float)
- RT : 3Ã—4 ou 4Ã—4 (float)

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : Trop/pas assez de clusters

**Solution** : Ajuster `eps` dans `cluster_points()`
```python
# Augmenter eps pour fusionner plus de points
clusters = metrics.cluster_points(eps=0.010)

# RÃ©duire eps pour sÃ©parer les points
clusters = metrics.cluster_points(eps=0.003)
```

### ProblÃ¨me : Erreur "No points in cluster"

**Cause** : `min_samples` trop Ã©levÃ©

**Solution** :
```python
clusters = metrics.cluster_points(eps=0.005, min_samples=2)
```

### ProblÃ¨me : Depth map vide aprÃ¨s dÃ©projection

**Causes possibles** :
1. Mauvaise matrice K (vÃ©rifier fx, fy, cx, cy)
2. Mauvais `depth_scale` (vÃ©rifier unitÃ©s)
3. Tous les pixels sont invalides (vÃ©rifier depth_map > 0)

**Debug** :
```python
print(f"Pixels non-nuls : {np.sum(depth_map > 0)}")
print(f"Range depth : [{np.min(depth_map[depth_map>0])}, {np.max(depth_map)}]")
```

---

## ğŸ“š RÃ©fÃ©rences

**Algorithmes utilisÃ©s :**
- DBSCAN clustering : Ester et al. (1996)
- PCA pour ellipses : Pearson (1901)
- Point-to-mesh distance : Trimesh library
- ICP (si nÃ©cessaire) : Besl & McKay (1992)

**MÃ©triques standards :**
- ISO 10360 : SpÃ©cifications gÃ©omÃ©triques des CMM
- VDI/VDE 2634 : Imagerie optique 3D

---

## ğŸ“„ Licence

MIT License - Libre d'utilisation

## ğŸ¤ Contribution

N'hÃ©sitez pas Ã  ouvrir des issues ou proposer des amÃ©liorations !
